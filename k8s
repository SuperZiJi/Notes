k8s架构
	1、etcd：保存了整个集群的状态；
	2、apiserver提供了资源操作的唯一入口、并提供认证、授权、访问控制、API注册和发现等机制。
	3、controller manager负责维护集群的状态，比如故障检测、自动扩展、滚动更新等；
	4、scheduler负责资源的调度，按照预定的调度策略，将pod调度到相应的机器上；
	5、kubelet负责维护容器的生命周期，也负责volume（CVI）和网络(CNI)的管理
	6、Container runtime负责镜像的管理以及Pod和容器的真正运行(CRI)
	7、kube-proxy负责为service提供cluster内部的服务发现和负载均衡
	
	一些add-ons:
	kube-dns负责为整个集群提供dns服务
	Ingress Controller为服务提供外网入口
	Heapster提供资源监控
	Dashboard提供GUI
	Federation提供跨可用区的集群
	Fluentd-elasticsearch提供集群日志采集、存储与查询

k8s设计理念
	
创建k8s对象
	kubectl create -f xxxxxxx.yaml --record
	其中yaml文件必填字段
	apiVersion 创建对象的kubernetes API版本
	kind　创建对象的种类
	metadata 具有唯一标示对象的数据，包括name、uid、namespace

k8s　Names
	Name在一个对象中同一时间只能拥有单个Name,若果对象被删除，也可以使用想退Name创建新的对象
　　　　UIDs
	是k8s生成的，在k8s集群的整个生命周期中创建的每个对象都有不同的UID（他们在时间和空间上是唯一的）

k8s Namespaces
	是一种将其群资源划分为多个用途的方法
	创建
	1、kubectl create namespace new-namespace   //命令创建
	2、kubectl create -f xxxxxx.yaml 	    //文件创建
	删除
	1、kubectl delete namespaces xxxxxx
	2、删除一个namespace会删除属于该namespace的资源
	3、default和kube-system命名空间不可删除
	4、PersistentVolunes是不属于任何namespace的，但是PersistentVolumeClaim是属于某个特定namespace的
	5、Events是否属于namespae取决于产生events的对象
	查看
	1、kubectl get namespaces
	k8s从两个初始的Namespace开始　default、kube-system
	2、临时设置namespace
	kubectl --namespace=<xxxxxxxxx> run nginx --image=nginx
	kubectl --namespace=<xxxxxxxxx> get pods
	3、所有对象都在namespace中？
	大多数Kubernetes资源（例如pod、services、replication controllers或其他）都在某些Namespace中，但Namespace
	资源本身并不在Namespace中。而低级别资源（如Node和persistentVolumes）不在任何Namespace中。Events是一个例
	外：它们可能有也可能没有Namespace，具体取决于Events的对象。

k8s　Volume
	默认情况下，容器的磁盘的文件是非持久化的，所以存在两个问题
	1、容器挂掉或k8s重启它的时候，文件将会丢失
	2、Pod中同事运行多个容器，容器之间需要共享文件
	3、docker也有volume概念，但是生命周期不受管理，虽然docker也支持数据持久化存储，但是支持功能比较少
	例如：每个容器只能挂载一个volume，并且不能将参数传递给volume
	但是,k8s的volume具有明确的生命周期，和pod相同。因此，volume的生命周期比pod中运行的任何容器都要持久
	在，容器重新启动时能可以保留数据，当然，当pod被删除不存在时，Volume也将消失。k8s支持多种类型
	的volume，也可以同时使用任意类型/数量的volume。
	使用volume，pod需要制定volume的类型和内容（spec.volumes字段）,和映射到容器的位置(spec.containers.volumeMounts字段)	
	4、volume类型
	(......使用时查阅)

k8s pod
	1、Pod是k8s对象模型中可部署的最小对象
	2、一个pod代表集群上正在运行的一个进程
	3、一个pod可以运行一个或多个容器，存储资源、一个独立的网络ip以及管理控制容器运行方式的策略选项。
	4、每个pod都是运行应用的单个实例，如果需要水平扩展应用，应该使用多个pod。k8s中称为Replication,Replication
	的pod由Controller创建和管理。
	5、Pod如何管理多个容器
	容器间共享资源、网络和相互依赖关系，并同时被调度使用。
	Pods提供两种共享资源：网络和存储
	6、pod的网络
	每个Pod被分配一个独立的ip地址，pod中每个容器共享网络命名空间，包括ip地址和网络端口。Pod内的容器可以使用
	localhost来相互通信。当Pod中容器与Pod外部通信时，他们必须协调如何使用共享网络资源。
	7、Pod的存储
	Pod可以指定一组共享存储volumes。Pod中所有容器都可以访问共享volumes，允许这些容器共享数据。volumes可以用于
	pod中数据持久化，防止容器重启导致数据丢失。
	8、使用pod
	pod的生命周期是短暂的，用后即焚的实体。当pod被创建后，都会被k8s调度到集群的Node上。直到pod进程终止、被删除
	缺少资源被驱逐、或者node故障之前,这个pod都会一直保持在那个node上。
	注意：Pod只提供容器的运行环境并保持容器的运行状态，重启容器不会造成pod重启
	9、pod和controller
	controller可以创建和管理多个pod，提供副本管理、滚动升级和集群级别的自愈能力。例如，如果一个Node故障
	controller能够自动将该节点的Pod调度到其它健康的Node上

k8s　Node
	1、node是k8s的工作节点，一个node可以使vm或物理机。每个node具有运行pod的一些必要服务，并由master组件进项管理。
	node节点上的服务包括docker、kubelet和kube-proxy。
	2、Node status
		Addresses:
			hostName:可以通过kubelet中 --hostname-override参数覆盖
			externalIp:可以被集群外部路由到的ip
			internalIp:只能在集群内部进行路由的节点的ip地址
		Condition：
			描述所有Running节点的状态。
			OutOfDisk:　　true:没有足够空间来添加新的pod；false:有空间
			Ready:	true:节点健康，并准备好接收pod　　　　false:不健康且不接收pod　　　unknown:节点控制器在过去４０秒内灭有收到node的状态报告
			MemoryPressure:　true:节点存储器上内存过低，　false:内存充足
			DiskPressure:	true:磁盘容量存在压力　　　false:无压力
		被表示为一个json对象："coditions":[{"kind":"Ready","status":"True"}]
		Capacity:描述节点上可用的资源：cpu、内存和可以调度节点上的最大pod数
		Info：关于节点的一些基础信息，例如内核版本，k8s版本,kubelet和kube-proxy版本、docker版本。信息由kubelet从节点收集。
	3、Management
		与pods和services不同，节点不是由Kubernetes系统创建，它是由Google　Compute Engine等云提供商在外部创建的，或使用物理和虚拟机。
		这意味着,k8s创建节点时，只是创建一个代表节点的对象，创建后，kubernetes将检查节点是否有效。
		{
		  "kind": "Node",
		  "apiVersion": "v1",
		  "metadata": {
		    "name": "10.240.79.157",
		    "labels": {
		      "name": "my-first-k8s-node"
		    }
		  }
		}
		Kubernetes将在内部创建一个节点对象，基于metadata.name字段的健康检查来验证节点。k8s将保留无效节点对象，除非客户端有明确删除它，并且它将继续检
		查它是否变得有效
		目前，有三个组件与k8s节点接口进行交互:节点控制器（node controller)、kubelet和kubectl
	4、Node　Controller
		节点控制器，是管理节点的k8s master组件
		节点控制器在节点的生命周期中具有多个角色。
		1、注册时将CIDR块分配给节点。
		2、使节点控制器内部列表与云提供商的可用机器列表保持最新。当在云环境中运行时，每当节点不健康时，节点控制器将询问云提供程序是否该节点的ＶＭ仍然
			仍然可用，如果不可用，节点控制器会从节点列表中删除该节点。
		3、检测节点的健康状况。当节点变为不可访问时，节点控制器将负责将NodeStatus的NodeReady条件更新为ConditionUnknown,随后从节点中卸载所有的pod，r
			如果节点继续无法访问（默认超时时间为40　--node-monitor-period秒,开始报告ConditionUnknown，之后为5m开始卸载）。节点控制器按照每秒来检
			查每个节点的状态。

k8s service
	pod是有生命周期的，可以创建和销毁，一旦销毁，生命就永远结束。ReplicationController能够动态的创建和销毁
	每个pod都会获取它自己的ip地址，及时这些ip地址不总是稳定可依赖的。这会导致一个问题：在k8s集群中，如果一组pod为
	其它pod提供服务，那么这些frontend该如何发现，并连接到这组pod。
	1、关于service
	k8s　service定义了这样一种抽象：一个pod的逻辑分组，一种可以可以访问他们的策略————通常称为微服务。
	2、例如：一个图片处理backend，运行了三个副本，frontend不需要知道这一组backend成的pod实际变化，也不需要知道它调用了
	哪一个具体的pod。
	对k8s集群中的应用，k8s提供简单的endpoints　api，只要service中的一组pod发生变更，应用程序就会被更新。
	对非k8s集群的应用，k8s提供基于vip网桥方式访问service，再由service　重定向到backend pod.
	3、定义service
	一个service在k8s中是一个REST对象，和pod类似，Service定义可以基于post方式，请求apiServer创建新的实例。
	例如，有一组pod，他们对外暴露了9376端口，同时被打上app=MyApp的标签
	kind: Service
	apiVersion: v1
	metadata:
	  name: my-service
	spec:
	  selector:
	    app: MyApp
	  ports:
	    - protocol: TCP
	      port: 80
	      targetPort: 9376
	上述配置将创建一个名称为：my-service的Service对象,它会请求代理使用tcp端口9376
	且具有标签app=MyApp的Pod上。这个Service将被指派一个IP地址（cluster IP）,它会被服务的代理使用。该Service的selector将会持续评估
	处理结果将被post到一个名为my-service的Endpoints对象上。
	注意：Service能够将一个接收端口映射到任意的targetPort。默认相同。
	4、定义没有selector的Service
		场景：
		    希望在生产环境中使用外部的数据库集群，但测试环境使用自己的数据库。
		    希望服务指向另一个 Namespace 中或其它集群中的服务。
		    正在将工作负载转移到 Kubernetes 集群，和运行在 Kubernetes 集群之外的 backend。


k8s　master-node通信
	1、cluster->master
	从集群到master节点的所有通信路径都在apiserver中终止，一个典型的deployment，如果apiserver配置为坚挺
	运程连接上的https　443端口,应启用一种或多种client　authentication,特别是如果允许anonymous requests或service　account　tokens。
	Node节点应配置为集群的公共根证书，以便安全的连接到apiserver。
	2、
